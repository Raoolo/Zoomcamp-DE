{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f46e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f44ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/29 15:17:01 WARN Utils: Your hostname, RaulPC resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/08/29 15:17:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/29 15:17:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "# this is an object used to interact with spark, the entry-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d39c9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-29 15:22:35--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.165.247.79, 3.165.247.187, 3.165.247.72, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.165.247.79|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 308924937 (295M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘fhvhv_tripdata_2021-01.parquet’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 294.61M  8.57MB/s    in 39s     \n",
      "\n",
      "2024-08-29 15:23:14 (7.65 MB/s) - ‘fhvhv_tripdata_2021-01.parquet’ saved [308924937/308924937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c74b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('fhvhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d50ab70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime=datetime.datetime(2021, 1, 1, 1, 28, 9), on_scene_datetime=datetime.datetime(2021, 1, 1, 1, 31, 42), pickup_datetime=datetime.datetime(2021, 1, 1, 1, 33, 44), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 49, 7), PULocationID=230, DOLocationID=166, trip_miles=5.26, trip_time=923, base_passenger_fare=22.28, tolls=0.0, bcf=0.67, sales_tax=1.98, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=14.99, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime=datetime.datetime(2021, 1, 1, 1, 45, 56), on_scene_datetime=datetime.datetime(2021, 1, 1, 1, 55, 19), pickup_datetime=datetime.datetime(2021, 1, 1, 1, 55, 19), dropoff_datetime=datetime.datetime(2021, 1, 1, 2, 18, 21), PULocationID=152, DOLocationID=167, trip_miles=3.65, trip_time=1382, base_passenger_fare=18.36, tolls=0.0, bcf=0.55, sales_tax=1.63, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=17.06, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime=datetime.datetime(2021, 1, 1, 1, 21, 15), on_scene_datetime=datetime.datetime(2021, 1, 1, 1, 22, 41), pickup_datetime=datetime.datetime(2021, 1, 1, 1, 23, 56), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 38, 5), PULocationID=233, DOLocationID=142, trip_miles=3.51, trip_time=849, base_passenger_fare=14.05, tolls=0.0, bcf=0.48, sales_tax=1.25, congestion_surcharge=2.75, airport_fee=None, tips=0.94, driver_pay=12.98, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime=datetime.datetime(2021, 1, 1, 1, 39, 12), on_scene_datetime=datetime.datetime(2021, 1, 1, 1, 42, 37), pickup_datetime=datetime.datetime(2021, 1, 1, 1, 42, 51), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 45, 50), PULocationID=142, DOLocationID=143, trip_miles=0.74, trip_time=179, base_passenger_fare=7.91, tolls=0.0, bcf=0.24, sales_tax=0.7, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=7.41, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime=datetime.datetime(2021, 1, 1, 1, 46, 11), on_scene_datetime=datetime.datetime(2021, 1, 1, 1, 47, 17), pickup_datetime=datetime.datetime(2021, 1, 1, 1, 48, 14), dropoff_datetime=datetime.datetime(2021, 1, 1, 2, 8, 42), PULocationID=143, DOLocationID=78, trip_miles=9.2, trip_time=1228, base_passenger_fare=27.11, tolls=0.0, bcf=0.81, sales_tax=2.41, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=22.44, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5) # it does not infer the type of csv, but parquet does not have this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78a582c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('originating_base_num', StringType(), True), StructField('request_datetime', TimestampType(), True), StructField('on_scene_datetime', TimestampType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropoff_datetime', TimestampType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('trip_miles', DoubleType(), True), StructField('trip_time', LongType(), True), StructField('base_passenger_fare', DoubleType(), True), StructField('tolls', DoubleType(), True), StructField('bcf', DoubleType(), True), StructField('sales_tax', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True), StructField('tips', DoubleType(), True), StructField('driver_pay', DoubleType(), True), StructField('shared_request_flag', StringType(), True), StructField('shared_match_flag', StringType(), True), StructField('access_a_ride_flag', StringType(), True), StructField('wav_request_flag', StringType(), True), StructField('wav_match_flag', StringType(), True)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema   # everything is a string in csv (not here btw), check the code of ex 4 week 5 for the infering of types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca766e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to create many partitions from the large single file\n",
    "df = df.repartition(24)   # this is lazy, does not trigger until the next action is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af67e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                         (0 + 8) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/29 15:38:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:===================>                                      (8 + 8) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/29 15:38:58 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:=====================>                                    (9 + 8) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/29 15:39:03 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:======================================>                  (16 + 8) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/29 15:39:03 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/01/', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b23a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp (nullable = true)\n",
      " |-- on_scene_datetime: timestamp (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c77d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|    pickup_datetime|   dropoff_datetime|\n",
      "+-------------------+-------------------+\n",
      "|2021-01-12 16:30:40|2021-01-12 17:08:15|\n",
      "|2021-01-31 15:51:25|2021-01-31 16:14:06|\n",
      "|2021-01-02 17:56:36|2021-01-02 18:43:44|\n",
      "|2021-01-16 19:31:36|2021-01-16 19:42:09|\n",
      "|2021-01-08 22:18:46|2021-01-08 22:25:25|\n",
      "|2021-01-21 13:40:46|2021-01-21 13:48:52|\n",
      "|2021-01-16 20:03:40|2021-01-16 20:10:20|\n",
      "|2021-01-04 06:24:56|2021-01-04 06:30:51|\n",
      "|2021-01-08 15:22:38|2021-01-08 15:34:42|\n",
      "|2021-01-16 21:35:50|2021-01-16 21:47:50|\n",
      "|2021-01-24 22:32:43|2021-01-24 22:57:19|\n",
      "|2021-01-20 00:25:30|2021-01-20 00:41:13|\n",
      "|2021-01-15 16:42:20|2021-01-15 16:52:34|\n",
      "|2021-01-28 20:33:36|2021-01-28 20:49:19|\n",
      "|2021-01-10 20:39:03|2021-01-10 20:46:45|\n",
      "|2021-01-10 01:26:38|2021-01-10 01:34:48|\n",
      "|2021-01-22 17:03:38|2021-01-22 17:20:57|\n",
      "|2021-01-27 21:24:35|2021-01-27 21:39:28|\n",
      "|2021-01-20 03:05:18|2021-01-20 03:26:38|\n",
      "|2021-01-17 15:36:45|2021-01-17 15:42:07|\n",
      "+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropoff_datetime').filter(df.hvfhs_license_num == 'HV0003').show()  # filter is lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06cdf321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313da0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+\n",
      "|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------+------------+------------+------------+\n",
      "| 2021-01-26|  2021-01-26|         247|         200|\n",
      "| 2021-01-29|  2021-01-29|          61|         119|\n",
      "| 2021-01-27|  2021-01-27|         248|         182|\n",
      "| 2021-01-04|  2021-01-04|         225|          97|\n",
      "| 2021-01-25|  2021-01-25|         233|         140|\n",
      "| 2021-01-15|  2021-01-15|          20|         265|\n",
      "| 2021-01-23|  2021-01-23|         137|         226|\n",
      "| 2021-01-20|  2021-01-20|         126|         254|\n",
      "| 2021-01-23|  2021-01-23|          50|         166|\n",
      "| 2021-01-01|  2021-01-01|          28|         129|\n",
      "| 2021-01-23|  2021-01-23|          68|         265|\n",
      "| 2021-01-28|  2021-01-28|          28|         134|\n",
      "| 2021-01-15|  2021-01-15|         159|          18|\n",
      "| 2021-01-05|  2021-01-05|          37|         256|\n",
      "| 2021-01-04|  2021-01-04|          35|         177|\n",
      "| 2021-01-17|  2021-01-17|          85|          35|\n",
      "| 2021-01-30|  2021-01-30|         240|          82|\n",
      "| 2021-01-30|  2021-01-30|         226|         142|\n",
      "| 2021-01-13|  2021-01-13|         254|          51|\n",
      "| 2021-01-06|  2021-01-06|         126|         126|\n",
      "+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .select('pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()\n",
    "\n",
    " # transformation that adds new column pickup_date and insert the to_date(pickup_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf578dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab71e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9bcb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can create user defined functions (UDF) like this \n",
    "crazy_stuff_udf=F.udf(crazy_stuff,  returnType= types.StringType())\n",
    "# and then you apply it similarly to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4e0a2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 19:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-------+------------+------------+\n",
      "|pickup_date|dropoff_date|base_id|PULocationID|DOLocationID|\n",
      "+-----------+------------+-------+------------+------------+\n",
      "| 2021-01-19|  2021-01-19|  e/b3b|         208|         254|\n",
      "| 2021-01-12|  2021-01-12|  s/b44|          72|          72|\n",
      "| 2021-01-22|  2021-01-22|  e/b38|          72|          39|\n",
      "| 2021-01-17|  2021-01-17|  e/9ce|         198|         196|\n",
      "| 2021-01-06|  2021-01-06|  s/b3d|         169|          74|\n",
      "| 2021-01-05|  2021-01-05|  e/b38|         165|         225|\n",
      "| 2021-01-12|  2021-01-12|  e/b3e|          56|         129|\n",
      "| 2021-01-05|  2021-01-05|  e/9ce|         225|          97|\n",
      "| 2021-01-13|  2021-01-13|  s/b3d|          37|          37|\n",
      "| 2021-01-23|  2021-01-23|  e/b30|          87|         107|\n",
      "| 2021-01-22|  2021-01-22|  e/9ce|         182|         127|\n",
      "| 2021-01-16|  2021-01-16|  e/acc|          17|         188|\n",
      "| 2021-01-09|  2021-01-09|  e/9ce|          61|         188|\n",
      "| 2021-01-14|  2021-01-14|  e/b3b|         163|         233|\n",
      "| 2021-01-24|  2021-01-24|  e/b35|         206|         156|\n",
      "| 2021-01-09|  2021-01-09|  e/b3b|          39|          39|\n",
      "| 2021-01-08|  2021-01-08|  e/b35|         173|          49|\n",
      "| 2021-01-28|  2021-01-28|  e/9ce|           7|         193|\n",
      "| 2021-01-27|  2021-01-27|  e/b35|         121|          10|\n",
      "| 2021-01-02|  2021-01-02|  e/9ce|         220|          59|\n",
      "+-----------+------------+-------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num))\\\n",
    "    .select('pickup_date', 'dropoff_date', 'base_id', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
